## Copiloto Conversacional sobre Documentos
### üìù Descripci√≥n del proyecto

Este proyecto implementa un copiloto conversacional que permite a un usuario subir hasta 5 archivos PDF y hacer 
reguntas en lenguaje natural sobre su contenido. Las respuestas se generan de manera contextual, utilizando un flujo de 
procesamiento y almacenamiento estructurado de la informaci√≥n en estructura Rack.

El objetivo principal es demostrar habilidades en dise√±o de microservicios,
integraci√≥n de LLMs y vector stores, y orquestaci√≥n de flujos conversacionales escalables.

## ‚öôÔ∏è Arquitectura del sistema

Esta es una arquitectura RACK (Recuperaci√≥n Asistida por Conocimiento), basada en las siguientes tecnolog√≠as:

Backend: NestJS (microservicio)
Elegido por su escalabilidad y patr√≥n de dise√±o modular.

LLM: GPT-3.5-turbo
Seleccionado por su versatilidad y capacidad de razonamiento l√≥gico.

Embedding model: text-embedding-3-small
Optimizado por rendimiento y costo para generar vectores de los documentos.

Vector Store: Chroma
Base de datos vectorial para b√∫squedas sem√°nticas r√°pidas.

Interfaz: Web app (Vue 3)
Permite subir PDFs y mantener la conversaci√≥n con el asistente.



## üîÑ Flujo conversacional

Subida de documentos:
El usuario sube hasta 5 PDFs.

Procesamiento de documentos:
Los PDFs se separan en chunks (segmentos de texto) para mejorar el rendimiento de b√∫squeda y la precisi√≥n de los embeddings.
Cada chunk se transforma en un vector mediante text-embedding-3-small.

Almacenamiento:
Los vectores se guardan en Chroma, permitiendo b√∫squedas sem√°nticas eficientes.

Consulta del usuario:
Cada pregunta se transforma en embedding y se consulta en Chroma.
Los documentos m√°s relevantes se env√≠an al LLM junto con la memoria conversacional y un prompt de orientaci√≥n, asegurando respuestas contextuales y coherentes.

Respuesta:
GPT-3.5-turbo genera la respuesta final bas√°ndose en la informaci√≥n recuperada y el contexto de la conversaci√≥n.

## üöÄ Funcionalidades
Funcionalidades implementadas

Subida de hasta 5 PDFs.
Extracci√≥n, chunking y vectorizaci√≥n de contenido.
B√∫squeda sem√°ntica y recuperaci√≥n de informaci√≥n.
Interfaz conversacional con memoria contextual.


## üõ†Ô∏è Tecnolog√≠as
Componente	Tecnolog√≠a	Justificaci√≥n
Backend	NestJS (microservicio):	Escalabilidad, modularidad y patrones de dise√±o claros.
LLM	GPT-3.5-turbo:	Versatilidad y l√≥gica avanzada en generaci√≥n de texto.
Embeddings	text-embedding-3-small:	Buen rendimiento y costo-efectivo.
Vector Store	Chroma:	Recuperaci√≥n sem√°ntica r√°pida y confiable.
Frontend	Vue 3:	Interfaz reactiva y manejable.


## ‚ö†Ô∏è Limitaciones y mejoras futuras

No se implementa a√∫n la comparaci√≥n autom√°tica de documentos ni clasificaci√≥n avanzada.

Mejora futura: 
resumir autom√°ticamente documentos largos y a√±adir alertas de inconsistencias.

Escalabilidad futura: 
implementar pipelines de procesamiento asincr√≥nico para grandes vol√∫menes de PDFs.